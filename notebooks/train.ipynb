{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import clone\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from pyearth import Earth\n",
    "from copy import deepcopy\n",
    "from sklearn.ensemble import partial_dependence as pd\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = np.load('data.npz')\n",
    "X_full = dataset['X']\n",
    "X_full = X_full.reshape((X_full.shape[0], -1))\n",
    "y = dataset['nMCparticles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "imp = []\n",
    "\n",
    "def train_and_get_results(reg, X_full, y, score_fn=r2_score, n_folds=5):\n",
    "    X = X_full    \n",
    "    folds = KFold(X.shape[0], n_folds=n_folds)\n",
    "    scores_train = []\n",
    "    scores_test = []\n",
    "    models = []\n",
    "    for train, test in folds:\n",
    "        reg_ = clone(reg)\n",
    "\n",
    "        m = y[train].mean()\n",
    "        s = y[train].std()\n",
    "\n",
    "        \n",
    "        reg_.fit(X[train], (y[train]))\n",
    "\n",
    "        score = score_fn(y[train], (reg_.predict(X[train])))\n",
    "        scores_train.append(score)\n",
    "\n",
    "        score = score_fn(y[test] , (reg_.predict(X[test])))\n",
    "        scores_test.append(score)\n",
    "        models.append(reg_)\n",
    "        if hasattr(reg_, 'feature_importances_'):\n",
    "            imp.append(reg_.feature_importances_)\n",
    "    return scores_train, scores_test, models\n",
    "\n",
    "rf_param_dist = {\"max_depth\": sp_randint(1, 100),\n",
    "              \"n_estimators\": sp_randint(1, 100),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False]}\n",
    "gb_params_dist= {\n",
    "    \"learning_rate\": sp_uniform(0, 1), \n",
    "    \"n_estimators\": sp_randint(1, 200), \n",
    "    \"max_depth\": sp_randint(1, 100)\n",
    "}\n",
    "regs = [\n",
    "    DummyClassifier(),\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(max_depth=30, n_estimators=50),\n",
    "    GradientBoostingClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_fn = accuracy_score\n",
    "results = map(lambda reg:train_and_get_results(reg, X_full, y, score_fn=score_fn, n_folds=5), regs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_mean = np.array([np.mean(scores_test) for scores_train, scores_test, models in results])\n",
    "test_std = np.array([np.std(scores_test) for scores_train, scores_test, models in results])\n",
    "\n",
    "train_mean = [np.mean(scores_train) for scores_train, scores_test, models in results]\n",
    "train_std = [np.std(scores_train) for scores_train, scores_test, models in results]\n",
    "\n",
    "names = [reg.__class__.__name__.replace('Regressor', '').replace('Dummy', 'Constant') for reg in regs]\n",
    "ind = np.arange(len(regs))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "width = 0.8\n",
    "plt.xticks(ind + width/2., names)\n",
    "rects = plt.bar(ind, test_mean / test_mean.max(), width=width, color='blue')\n",
    "for i, rect in enumerate(rects):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2., 1.05 * height,\n",
    "            '%.2f +/- %.3f' % (test_mean[i], test_std[i] ),\n",
    "             ha='center', va='bottom')\n",
    "plt.ylabel('{}'.format(score_fn.__name__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
